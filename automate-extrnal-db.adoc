## Provisioning External Databases

In previous lab we created an pipeline to deploy our catalog service and Web UI to *Coolstore STAGE* project. It uses not MySQL database provisioned from standard Openshift templates. In this lab we will provision external database from Digital Ocean with Ansible Playbook Bundle (APB) and link that to Coolstore catalog service.

You will be executing following steps

* Create, Build and Push APB to Openshift DEV Cluster
* Provision external database with APB
* Link external database to catalog service.

### Introduction to Ansible Playbook Bundles

An APB is a lightweight application definition that borrows several concepts from the Nulecule and Atomicapp projects, namely the concept of a short-lived container with the sole purpose of orchestrating the deployment of the intended application. For the case of APBs, this short-lived container is the APB itself: a container with an Ansible runtime environment plus any files required to assist in orchestration, such as playbooks, roles, and extra dependencies.

The OpenShift Ansible broker (OAB) is an implementation of the Open Service Broker (OSB) API that manages applications defined by APBs. The OAB is supported and deployed by default starting in OpenShift Container Platform 3.7.

Specification of an APB is intended to be lightweight, consisting of several named playbooks and a metadata file to capture information such as parameters to pass into the application.

### APB workflow

Workflow
The APB workflow is broken up into the following steps:

. Preparation
.. APB initialization
.. APB spec file
.. Actions (provision, deprovision, bind, unbind)
. Build
. Deploy

#### Preparation
You must prepare your APB’s directory structure and spec file before you can build and deploy it. The https://docs.openshift.com/container-platform/3.9/apb_devel/writing/getting_started.html#apb-devel-writing-getting-started[Getting Started] topic provides a step by step tutorial on creating your first APB, while the following sections briefly cover this workflow.

#### APB initialization

The apb init command creates the required skeleton directory structure and a few required files (for example, the apb.yml spec file) for the APB.

#### APB Spec file

An APB spec file (apb.yml) must be edited for your specific application.

#### Actions

The following are the actions for an APB. At a minimum, an APB must implement the provision and deprovision actions:

provision.yml:: Playbook called to handle installing application to the cluster.

deprovision.yml:: Playbook called to handle uninstalling.

bind.yml:: Playbook to grant access to another service to use this service, such as generating credentials.

unbind.yml:: Playbook to revoke access to this service.

test.yml:: (Optional) Playbook to test that the APB is vaild.

The required named playbooks correspond to methods defined by the OSB API. For example, when the OAB needs to provision an APB it will execute *provision.yml*.

After the required named playbooks have been generated, the files can be used directly to test management of the application. A developer may want to work with this directory of files, make tweaks, run, repeat until they are happy with the behavior. They can test the playbooks by invoking Ansible directly with the playbook and any required variables.

#### Build

The build step is responsible for building a container image from the named playbooks for distribution. Packaging combines a base image containing an Ansible runtime with Ansible artifacts and any dependencies required to run the playbooks.

The result is a container image with an *ENTRYPOINT* set to take in several arguments, one of which is the method to execute, such as provision and deprovision.

#### Deploy

Deploying an APB means invoking the container and passing in the name of the playbook to execute along with any required variables. It is possible to invoke the APB directly without going through the OAB. Each APB is packaged so its ENTRYPOINT will invoke Ansible when run. The container is intended to be short-lived, coming up to execute the Ansible playbook for managing the application then exiting.

In a typical APB deploy, the APB container will provision an application by running the provision.yml playbook, which executes an Ansible role. The role is responsible for creating the OpenShift Container Platform resources, perhaps through calling oc create commands or leveraging Ansible modules. The end result is that the APB runs Ansible to talk to OpenShift Container Platform to orchestrate the provisioning of the intended application.

The following diagrams illustrate this deployment flow in two phases: a user discovering a list of available APBs and then requesting their chosen APB be provisioned to their project:

image::devops-externaldb-apb-deploy.png[Deploying APB diagram 1]


. An OpenShift Container Platform user is interested in provisioning a service into their project, so they interact with the service catalog by accessing the OpenShift Container Platform UI (web console or CLI) to discover any APBs that are already available.

. The service catalog requests a list of APBs from the OAB to show the user.

. The OAB searches all configured container registries (the cluster’s OpenShift Container Registry or any other remote registry) for any APBs (images with a specific label, for example LABEL=apb-1.0).

. The OAB returns the discovered list to the service catalog, to be viewed by the user in the OpenShift Container Platform UI.

image::devops-externaldb-apb-deploy-2.png[Deploying APB diagram 2]

[start=5]
. The user now chooses an APB from the discovered list provided by the service catalog.

. The service catalog communicates with the OAB that the user has requested use of the chosen APB.

. The OAB initiates the image pull from the appropriate container registry.

. After the image is pulled, the OAB defers the logic for orchestrating the application to the APB. The service is deployed by running the APB container with a few parameters. To do so, the following command is issued against the OpenShift Container Platform cluster in a temporary namespace:

. As a result, the user views via the OpenShift Container Platform UI that their requested service has been successfully provisioned in their project.

### Creating our own APB

Create an APB project using the APB CLI:

[source,shell,role=copypaste]
```
cd ~
apb init mysql-digital-ocean-apb --bindable
```

Take a look inside the `mysql-digital-ocean-apb` directory and review `apb.yml`

[source,shell,role=copypaste]
```
cd mysql-digital-ocean-apb
cat apb.yml
```

Define the parameters for the MySQL APB by replacing it with the following:

[source,shell,role=copypaste]
```
cat <<'EOF' > apb.yml
_params: &_params
  - name: service_name
    title: Database service name
    description: The name of the service. Used to name droplet and OpenShit service
    type: string
    default: domysql
    pattern: "^[a-zA-Z0-9]+[a-zA-Z0-9]*[a-zA-Z0-9]+$"
    required: true
  - name: region
    title: Target region
    description: Region where VM will be provisioned
    type: enum
    enum: [nyc1,nyc2,nyc3,sfo1,sfo2,ams2,ams3,sgp1,lon1,fra1,tor1,blr1]
    default: sfo1
    reguired: true
    display_type: select
  - name: mysql_database
    title: Database name
    description: The name of the MySQL database
    type: string
    default: catalog
    pattern: "^[a-zA-Z0-9_]*[a-zA-Z_]+[a-zA-Z0-9_]*$"
    required: true
  - name: mysql_user
    title: Database username
    description: Username that will be used to connect to MySQL
    type: string
    default: admin
    pattern: "^[a-zA-Z0-9_]*[a-zA-Z_]+[a-zA-Z0-9_]*$"
    required: true
  - name: mysql_password
    title: Database user password
    description: Password to connect to MySQL
    type: string
    required: true
    display_type: password
version: 1.0
name: mysql-digital-ocean-apb
description: MySQL database from Digital Ocean
bindable: true
async: optional
tags:
- database
- mysql
metadata:
  displayName: "Digital Ocean MySQL (APB)"
  longDescription: "MySQL 5.7 running on CentOs 7.4 in Digital Ocean"
  console.openshift.io/iconClass: icon-mysql-database
  providerDisplayName: "Red Hat, Inc."
plans:
  - name: 512mb
    description: Small droplet with MySQL
    free: true
    metadata:
      displayName: Default (512MB)
      longDescription: This plan provides small (512MB) droplet from Digital Ocean with MySQL
      cost: $0.00
    parameters: *_params
  - name: 2gb
    description: Small droplet with MySQL
    free: true
    metadata:
      displayName: Medium (2GB)
      longDescription: This plan provides medium (2GB) droplet from Digital Ocean with MySQL
      cost: $10.00 monthly
    parameters: *_params
  - name: 4gb
    description: Small droplet with MySQL
    free: true
    metadata:
      displayName: Large (4GB)
      longDescription: This plan provides large (4GB) droplet from Digital Ocean with MySQL
      cost: $40.00 monthly
    parameters: *_params
EOF
```

Explain how playbooks work in APBs and review the existing playbooks in `playbooks/`

Copy the existing roles and playbooks to use the Digital Oceal ansible modules avaialble
on Ansible Galaxy:

[source,shell,role=copypaste]
```
\cp -rf ~/support/mysql-digital-ocean-apb/{playbooks,roles} .     # \ is to disable the 'cp -i' alias
```

Explain the APB process (build docker image, push ,etc). Although APB CLI generates a Dockerfile since
you need some extra python libraries, replace it with this one:

[source,shell,role=copypaste]
```
cat <<'EOF' > Dockerfile
FROM openshift3/apb-base

LABEL "com.redhat.apb.spec"=\

RUN yum-config-manager --disable rhel-7-server-htb-rpms && yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm && yum -y update && yum -y install python git python-pip python-requests python-setuptools python-wheel && yum clean all
RUN pip install --upgrade pip --user apb --cache-dir /tmp && pip install --user apb 'dopy>=0.3.7,<=0.3.7' --cache-dir /tmp
RUN chown -R apb:0 /opt/apb && chmod -R g=u /opt/apb /etc/passwd

COPY playbooks /opt/apb/actions
COPY roles /opt/apb/actions/roles
RUN chmod -R g=u /opt/{ansible,apb}
USER apb
ENV ANSIBLE_HOST_KEY_CHECKING false

EOF
```

Now you are done with authoring the APB. Prepare it for distribution:

[source,shell,role=copypaste]
```
apb prepare
```
`
Review Dockerfile and note LABEL

Build the APB container image:

[source,shell,role=copypaste]
```
sudo apb build
```

Now you should add it to the service catalog. You have to log in as admin first since this is admin thing to do:

[source,shell,role=copypaste]
```
oc login -u admin -p openshift
apb push --registry-route {{ OPENSHIFT_REGISTRY }}
```

Log back in as your own user for rest of the labs

[source,shell,role=copypaste]
```
oc login -u {{ OPENSHIFT_USER }}
```

Go to the OpenShift Web Console and inside the STAGE project and in the _Search Catalog_ field search for
_Digital Ocean_  and click on **Digital Ocean MySQL* to provision it. Ansible playbooks inside our APB are using Digital Ocean Ansible module and also REST API. Both of those need Digital Ocean API key for authentication. Cluster admin can add secrets that will be injected to Ansible Playbook Bundle execution pods. We have already created secret with API key for you and configured it to be used in the provisioning.

If catalog item is not visible refresh Web Console or logout and log back in.

image::devops-externaldb-search-catalog.png[Search catalog for APB]

Once correct catalog item is selected you will be displayed general information about catalog item.

image::devops-externaldb-apb-general-info.png[General info about APB]

Service Broker API gives you possibility to have different plans in your Service Catalog items. This Ansible Playbook Bundle item has three plans 512mb, 2gb and 4gb. Default plan _512mb_ is already selected for you.

image::devops-externaldb-select-plan.png[Select plan]

All Service Catalog items accept parameters which you can use to tune your services to be provisioned. Different plans can have different parameters, but in this case parameters are the same for all plans. Parameters are defined in apb.yml file during APB creation process. All parameters is this catalog item are mandatory. You can choose to which Digital Ocean region you want your database to be provisioned. Default sfo1 is close so we'll use that. After parameters are set, scroll down and select _Next_

image::devops-externaldb-configuration.png[Configure your service]

When we provisioned Jenkins from Service Catalog we didn't create secret that can be bind to other applications in the projects. This time we need that secret so that catalog application knows how to connect to external database. We will link created secrets to catalog application later. Select _Create_ once you have changed default selection.

image::devops-externaldb-choose-bind-creds.png[Create secret for binding]

All done, next click _Continue to the project overview_. Add the and of the overview page you will se MySQL Digital Ocean services and its state under Provisioned Services. Provision and binding will take from 5-10 minutes.

image::devops-externaldb-provisioning-ongoing.png[Service provisioning]

Provisioning is executed in a pod in namespace which is created by Openshift Ansible Service Broker. This namespace and also pod have a random name, so we need to use labels to find correct project and pod. By default these provisioning and deprovisioning namesapaces are removed automatically. You can change this behaviour from Ansible Service Broker configuration.

Execute following commands to find correct namespace and then read pod logs. You need to pretty fast.

[source,shell,role=copypaste]
```
oc login -u admin -p openshift
oc project $(oc get project -l apb-fqname=localregistry-mysql-digital-ocean-apb --no-headers=true | awk '{print $1}')
oc logs -f $(oc get po -l apb-fqname=localregistry-mysql-digital-ocean-apb --no-headers=true | awk '{print $1}')
```

Log back in as your own user for rest of the labs

[source,shell,role=copypaste]
```
oc login -u {{ OPENSHIFT_USER }}
```

You can check is everything done by expanding service in STAGE project _Overview_ page

image::devops-externaldb-open-service.png[Expand service view]

When your secret is created for you, you should have options _Delete_ and _View Secret_. If those are not present, provisioning and binding is not ready yet. Select _View Secret_ to display information about secret.

image::devops-externaldb-view-secret.png[View secret]

From secret view you can add this secret to any application you have in your project. Select _Add to Application_ to continue.

image::devops-externaldb-add-to-application.png[Add secret to application]

Select _catalog_ and and _APB__ as environment variable prefix. By using prefix you will not accidentally overwrite some environment variables that you may already have. Select _Save_ when done.

image::devops-externaldb-select-application.png[Select application and give env prefix]

Now that all relevant information is bound to your application we need to start using those to get connection to external database. Catalog services uses configmap named catalog to configure connection to database. We will delete old configmap and create new with environment variables from APB.

Create new configmap

[source,shell,role=copypaste]
```
cat <<'EOF' > /tmp/application.properties
spring.datasource.url=jdbc:mysql://${APB_DB_SERVICE_NAME}:3306/${APB_DB_NAME}?useSSL=false
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.username=${APB_DB_USER}
spring.datasource.password=${APB_DB_PASSWORD}
spring.jpa.hibernate.ddl-auto=create
EOF
```

Delete old configmap

[source,shell,role=copypaste]
```
oc delete configmap catalog -n stage
```

Create new configmap and redeploy catalog

[source,shell,role=copypaste]
```
oc create configmap catalog --from-file=/tmp/application.properties -n stage
```

Now you have connected your application with external database running in Digital Ocean.
